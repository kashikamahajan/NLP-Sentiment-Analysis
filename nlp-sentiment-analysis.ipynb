{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **NLP Challenge: IMDB Dataset of 50K Movie Reviews to perform Sentiment analysis**\nThis model uses various NLP libraries to clean the movie reviews and then give a sentinent analysis (positive or negative) for a review. Due to technical restrictions, I was only able to train the model with 1000 reviews. The approach uses three forms of sentiment analysis and those are then pipelined into a Random Forest Regressor\n* TextBlob sentiment value\n* BERT sentiment analysis\n* k-means clustering","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy\nfrom nltk.stem.porter import *\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.cluster import KMeans\nfrom transformers import pipeline\nimport time\nfrom transformers import BertTokenizer\nimport math\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata=pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n\nclassifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-14T08:39:36.692993Z","iopub.execute_input":"2024-08-14T08:39:36.695968Z","iopub.status.idle":"2024-08-14T08:39:38.296271Z","shell.execute_reply.started":"2024-08-14T08:39:36.695900Z","shell.execute_reply":"2024-08-14T08:39:38.294784Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Dropping any duplicate or null values\n\ndata=data.dropna(axis=0,how='any')\ndata=data.drop_duplicates(subset='review')\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:38.298821Z","iopub.execute_input":"2024-08-14T08:39:38.299217Z","iopub.status.idle":"2024-08-14T08:39:38.472765Z","shell.execute_reply.started":"2024-08-14T08:39:38.299185Z","shell.execute_reply":"2024-08-14T08:39:38.471585Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                                   review sentiment\ncount                                               49582     49582\nunique                                              49582         2\ntop     One of the other reviewers has mentioned that ...  positive\nfreq                                                    1     24884","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>49582</td>\n      <td>49582</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>49582</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>24884</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Due to technical restraints, only 1000 reviews could have been analysed for a reasonable runtime\n\ndata=data.iloc[:5000]\nbert_data=data.iloc[:5000]","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:38.474591Z","iopub.execute_input":"2024-08-14T08:39:38.475094Z","iopub.status.idle":"2024-08-14T08:39:38.486646Z","shell.execute_reply.started":"2024-08-14T08:39:38.475049Z","shell.execute_reply":"2024-08-14T08:39:38.485269Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning**\nThe following blocks pertain to cleaning the data. The data is cleaned in two ways:\n* **K-means and spacy:** The data has any punctuation and stop words removed. The remaining words are then taken in their stem form, which will facilitate a more accurate word vectorisation for k-means\n* **BERT:** The data does not have its stop words or necessary punctuation removed. BERT needs stop words such as 'no, not, never' to make a more accurate analysis. ","metadata":{}},{"cell_type":"code","source":"#Loading variables to be used in functions below\n\nremove_chars='0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~'\nremove_bert_chars='\"#$%&\\'()*+-/:;<=>?@[\\\\]^_{|}~'\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:38.488663Z","iopub.execute_input":"2024-08-14T08:39:38.489081Z","iopub.status.idle":"2024-08-14T08:39:39.406505Z","shell.execute_reply.started":"2024-08-14T08:39:38.489047Z","shell.execute_reply":"2024-08-14T08:39:39.405475Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#method to clean data for spacy and kmeans\ndef clean_data(review):\n    \n    #Removing punctuation\n    for char in remove_chars:\n        review = review.replace(char, ' ')\n    \n    #Tokenisation using spacy\n    review=review.lower()\n    doc=nlp(review)\n    \n    #removing stop words\n    rem_words=[token.text for token in doc if not token.is_stop]\n    rem_review=\" \".join(rem_words)\n    review= rem_review\n    \n    #removing 'br' html tags and any word that is less than 3 letters\n    rem_words=[x for x in rem_words if not x==\"br\" and len(x)>2]\n    rem_review=\" \".join(rem_words)\n    review= rem_review\n    \n    #Lemmatization\n    doc=nlp(review)\n    rem_words=[token.lemma_ for token in doc if not token.is_stop]\n    rem_words=[x.strip() for x in rem_words]\n    rem_review=\" \".join(rem_words)\n    review= rem_review\n    \n    return str(review)\n\nstart=time.time()\n#data['review'] = data['review'].apply(lambda x: clean_data(x))\nend=time.time()\nprint('Time taken for data cleaning for kmeans and spacy:',(end-start))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:39.409410Z","iopub.execute_input":"2024-08-14T08:39:39.409775Z","iopub.status.idle":"2024-08-14T08:39:39.420509Z","shell.execute_reply.started":"2024-08-14T08:39:39.409745Z","shell.execute_reply":"2024-08-14T08:39:39.419236Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Time taken for data cleaning for kmeans and spacy: 3.0279159545898438e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"#method for cleaning data for BERT sentiment analysis\ndef clean_bert_data(rev):\n    #removing any punctuation which is not needed\n    for char in remove_bert_chars:\n        rev = rev.replace(char, '')\n    rev=rev.replace('br','')\n    rev=rev.lower()\n    return str(rev)\n\n\nstart=time.time()\nbert_data['review'] = bert_data['review'].apply(lambda x: clean_bert_data(x))\nend=time.time()\nprint('Time taken for data cleaning for BERT:',(end-start))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:39.422376Z","iopub.execute_input":"2024-08-14T08:39:39.422840Z","iopub.status.idle":"2024-08-14T08:39:39.582520Z","shell.execute_reply.started":"2024-08-14T08:39:39.422797Z","shell.execute_reply":"2024-08-14T08:39:39.581257Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Time taken for data cleaning for BERT: 0.14523983001708984\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Sentiment Analysis**\nThe next part of the code deals with using TextBlob and BERT for sentiment analysis\n* **TextBlob:**: Since the TextBlob sentiment analysis primarily focuses on the positive or negative words and their frequency, a more rigourisly cleaned form of the data is given. Any stop words and punctuation are removed. Only polarity is assessed in this form of analysis, not the subjectivity of the review. This austere form of sentimental analysis is helpful when models like BERT, which are more sensitive, give a wrong sentiment analysis, as seen in data[1] where mentions of gore and horor taint the label prediction resulting in NEGATIVE when it should be POSITIVE\n* **BERT:** While TextBlob gives a good enough prediciton of the sentiment, there are certain reviews, such as data[7] entry which due to use of negation,('not nearly good enough') is misinterpreted by the TextBlob sentiment analysis after remobing of stop words. BERT is more adept at analysing such reviews. \n\nBoth the models have their merits and demerits. Using both the models allows this program to predict the analysis accurately.","metadata":{}},{"cell_type":"code","source":"#method for getting the sentiment value of a review using TextBlob\ndef get_sent_values(review):\n    blob=TextBlob(review)\n    sent_values=[blob.sentiment.polarity,blob.sentiment.subjectivity]\n    #print(sent_values)\n    return sent_values\n\nstart=time.time()\ndata_sentiment=[]\nreviews=data['review']\ndata_sentiment.append(reviews.apply(lambda x: get_sent_values(x)))\ndata_sentiment=data_sentiment[0]\nend=time.time()\n\nprint('Time taken for sentiment analysis for TextBlob:',(end-start))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:39.583855Z","iopub.execute_input":"2024-08-14T08:39:39.584205Z","iopub.status.idle":"2024-08-14T08:39:48.540497Z","shell.execute_reply.started":"2024-08-14T08:39:39.584152Z","shell.execute_reply":"2024-08-14T08:39:48.539238Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Time taken for sentiment analysis for TextBlob: 8.949616432189941\n","output_type":"stream"}]},{"cell_type":"code","source":"#method for gettig the BERT sentiment analysis of a string and then sending a numerical value\ndef get_bert_values(sentence):\n    value=classifier(sentence)\n    value=value[0]\n    if(value['label'] == 'NEGATIVE'):\n        return(-1*value['score'])\n    else:\n        return(value['score'])\n    \n\n#method for cutting each review in chunks and sending it for BERT analysis and compiling the final sentiment value\ndef review_bert_analysis_by_sentence(review):\n    tokens = tokenizer(review, return_tensors='pt', truncation=False, padding=False)['input_ids']\n    max_chunk_size = 500\n\n    # Split the tokens into chunks of 512 tokens each since BERT transformer only takes 512 tokens at once\n    chunks = []\n    for i in range(0, tokens.size(1), max_chunk_size):  # Subtracting 2 to account for special tokens\n        chunk = tokens[:, i:i + max_chunk_size]\n        chunks.append(chunk)\n        \n    outputs = []\n    for chunk in chunks:\n        chunk_text = tokenizer.decode(chunk[0], skip_special_tokens=True)\n        output = get_bert_values(chunk_text)\n        outputs.append(output)\n\n    # Finding the mean of all sentiment values of a review\n    total_bert_value = np.mean(outputs)\n\n    return total_bert_value\n    \nstart=time.time()\nbert_values=bert_data['review'].apply(lambda x: review_bert_analysis_by_sentence(x))\nend=time.time()\nprint('Time taken for sentiment analysis for BERT:',(end-start))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T08:39:48.541819Z","iopub.execute_input":"2024-08-14T08:39:48.542149Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_sentiment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"polarity=[]\nfor row in data_sentiment:\n    polarity.append(row[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **KMEANS Approach**\nIn the next part, the data reviews are first vectorised and fit into a k-means model. The aim of this is to speed the prediction of sentiment as two clusters will be formed with one being positive and the other being negative. The predicted cluster will again be used in the RFR. \n\n[NOTE: In this version the kmeans value is not used in the final model as not enough data could have been processed to provide accurate kmeans clusters","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nX_v = vectorizer.fit_transform(data.review)\nX_a=X_v.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=2,n_init=10, random_state=1).fit(X_a)\nlabels=kmeans.labels_\nlabel_mapper={0:'positive',1:'negative'}\npredicted_labels_kmeans=[label_mapper[i] for i in labels]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Final Data Gathering**\nAll the values attained from data cleaning and analysis are then processed to be added to the dataframe which will be transformed and fit. To make the data more readble for humans when assessing accuracy it is mapped for words only for convienience. But to make the model more accurate, data is made numerical. ","metadata":{}},{"cell_type":"code","source":"predicted_labels_sentiment=['positive' if i > 0 else 'negative' for i in polarity]\nsentiment_mapper={'positive':0,'negative':1}\nnum_sentiment=[sentiment_mapper[i] for i in data.sentiment]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.insert(1, 'polarity',polarity, True )\ndata.insert(1, 'BERT values',bert_values, True )\ndata.insert(1, 'kmeans pred',labels, True )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.insert(4, 'sentiment_num',num_sentiment, True )\ndata[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Random Foresst Regressor**\nThe model is now being trained with the BERT values and polarity. Using this supervised machine learning model, the numerical data is used to predict the sentiment of a review, which is again a numerical value ranging from 0 to 1, since the original labels were mapped (positive: 0 and negative: 1)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nfeatures = ['BERT values','polarity']\nX = data[features]\ny = data.sentiment_num\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nrf_model = RandomForestRegressor(random_state=1)\n\nrf_model.fit(train_X, train_y)\nrf_pred=rf_model.predict(val_X)\n\n\nrf_val_mae = mean_absolute_error(rf_pred,val_y)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Since the predictions were made with a range of 0-1, the final prediction is further mapped to 0s and 1s \nnum_rf_pred=[]\nfor x in rf_pred:\n    if x<0.5:\n        num_rf_pred.append(0)\n    else: num_rf_pred.append(1)\nval_y=val_y.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Assessing Model Accuracy**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nscatter_plot_points = pca.fit_transform(X_a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\npca = PCA(n_components=2)\nscatter_plot_points = pca.fit_transform(X_a)\n\ncolors = [\"r\", \"b\"]\nx_axis = [o[0] for o in scatter_plot_points]\ny_axis = [o[1] for o in scatter_plot_points]\n\nplt.scatter(x_axis, y_axis, c=[colors[d] for d in labels])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels=data.sentiment.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(true_labels, predicted_labels_kmeans)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(true_labels, predicted_labels_sentiment)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Final Assessment**\nThe following Confusion Matrix visualises the accuracy of the above model with the predictions made for the testing data","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(val_y, num_rf_pred)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()\n\nlen(val_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}